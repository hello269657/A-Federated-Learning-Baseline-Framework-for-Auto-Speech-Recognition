import torch
import argparse
import numpy as np
from torch.utils.data import DataLoader
from flcore.trainmodel.models import FedAvgASRModel
from utils.data_utils import read_client_data, load_vocab
from flcore.clients.clientbase import Client


def parse_args():
    """è§£æå‚æ•°ï¼šåŒ…å«æ¨¡å‹ã€æ•°æ®ã€è¿è¡Œç›¸å…³é…ç½®"""
    parser = argparse.ArgumentParser(description="ç‹¬ç«‹WERæµ‹è¯•ç¨‹åºï¼ˆæå–è‡ªåŸæœ‰ä»£ç æ ¸å¿ƒé€»è¾‘ï¼‰")
    # -------------------------- 1. æ¨¡å‹ç›¸å…³ --------------------------
    parser.add_argument("-model_path", "--model_path", type=str,
                        default=r"D:",
                        help="æœ€ç»ˆèšåˆæ¨¡å‹çš„æƒé‡è·¯å¾„ï¼ˆå¦‚FedAvg_server.ptï¼‰")
    parser.add_argument("-mel_dim", "--mel_dim", type=int, default=80,
                        help="æ¢…å°”é¢‘è°±ç»´åº¦ï¼ˆè®­ç»ƒæ—¶è®¾ä¸º80ï¼Œä¸å¯ä¿®æ”¹ï¼‰")
    parser.add_argument("-hidden_dim", "--hidden_dim", type=int, default=256,
                        help="æ¨¡å‹éšè—å±‚ç»´åº¦ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰")
    parser.add_argument("-vocab_size", "--vocab_size", type=int, default=941,
                        help="è¯æ±‡è¡¨å¤§å°ï¼ˆå«<blank>ï¼Œä»dict.txtè¯»å–çš„å®é™…å¤§å°ï¼‰")


    # -------------------------- 2. æ•°æ®ç›¸å…³ --------------------------
    parser.add_argument("-dataset", "--dataset", type=str, default="THCHS30_ASR",
                        help="æ•°æ®é›†åç§°ï¼ˆéœ€ä¸data_utilsä¸­è¯»å–çš„æ•°æ®é›†ååŒ¹é…ï¼‰")
    parser.add_argument("-dict_path", "--dict_path", type=str,
                        default=r"D:",
                        help="è¯æ±‡è¡¨è·¯å¾„ï¼ˆä¸è®­ç»ƒæ—¶ä½¿ç”¨çš„dict.txtä¸€è‡´ï¼‰")
    parser.add_argument("-test_client_ids", "--test_client_ids", type=str, default="all",
                        help="æµ‹è¯•çš„å®¢æˆ·ç«¯IDï¼ˆå¦‚'0,1,2'æˆ–'all'è¡¨ç¤ºæ‰€æœ‰å®¢æˆ·ç«¯ï¼‰")
    parser.add_argument("-max_mel_len", "--max_mel_len", type=int, default=1600,
                        help="æ¢…å°”ç‰¹å¾æœ€å¤§é•¿åº¦ï¼ˆä¸data_utilsä¸­process_asr_dataé…ç½®ä¸€è‡´ï¼‰")
    parser.add_argument("-max_text_len", "--max_text_len", type=int, default=100,
                        help="æ–‡æœ¬æœ€å¤§é•¿åº¦ï¼ˆä¸data_utilsä¸­process_asr_dataé…ç½®ä¸€è‡´ï¼‰")

    # -------------------------- 3. è¿è¡Œç›¸å…³ --------------------------
    parser.add_argument("-device", "--device", type=str, default="cuda", choices=["cpu", "cuda"],
                        help="è®¡ç®—è®¾å¤‡ï¼ˆä¼˜å…ˆGPUï¼Œæ— GPUè‡ªåŠ¨åˆ‡CPUï¼‰")
    parser.add_argument("-batch_size", "--batch_size", type=int, default=10,
                        help="æµ‹è¯•æ‰¹æ¬¡å¤§å°ï¼ˆæ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼Œä¸å½±å“ç»“æœï¼‰")
    return parser.parse_args()


def init_wer_tools(dict_path):
    """åˆå§‹åŒ–WERè®¡ç®—å¿…éœ€çš„å·¥å…·ï¼šè¯æ±‡è¡¨æ˜ å°„ã€è§£ç å‡½æ•°"""
    # åŠ è½½è¯æ±‡è¡¨
    _, CHAR_TO_ID, ID_TO_CHAR = load_vocab(dict_path)
    print(f"âœ… åŠ è½½è¯æ±‡è¡¨æˆåŠŸï¼šå…±{len(ID_TO_CHAR)}ä¸ªç¬¦å·ï¼ˆ<blank> ID=0ï¼‰")

    class WERToolkit:
        @staticmethod
        def decode_ctc(pred_ids: np.ndarray) -> str:
            """CTCé¢„æµ‹ç»“æœè§£ç ï¼šç§»é™¤<blank>ï¼ˆID=0ï¼‰å’Œè¿ç»­é‡å¤æ ‡ç­¾"""
            pred_chars = []
            prev_id = -1
            for id in pred_ids:
                if id != CHAR_TO_ID["<blank>"] and id != prev_id:
                    pred_chars.append(ID_TO_CHAR.get(id, ""))
                    prev_id = id
            return " ".join(pred_chars)

        @staticmethod
        def decode_true_text(true_ids: np.ndarray, true_len: int) -> str:
            """çœŸå®æ ‡ç­¾è§£ç ï¼šä»…ç§»é™¤<blank>ï¼Œå–æœ‰æ•ˆé•¿åº¦"""
            valid_true_ids = true_ids[:true_len]
            true_chars = [ID_TO_CHAR.get(id, "") for id in valid_true_ids if id != CHAR_TO_ID["<blank>"]]
            return " ".join(true_chars)

        @staticmethod
        def calculate_wer(pred_text: str, true_text: str) -> float:
            """è®¡ç®—WERï¼šåŸºäºLevenshteinç¼–è¾‘è·ç¦»"""
            # åˆ†å‰²ä¸ºè¯ï¼ˆæ‹¼éŸ³ï¼‰åˆ—è¡¨
            pred_words = pred_text.strip().split()
            true_words = true_text.strip().split()
            # è®¡ç®—ç¼–è¾‘è·ç¦»
            print(f"é¢„æµ‹è¯åˆ—è¡¨: {pred_words}")
            print(f"çœŸå®è¯åˆ—è¡¨: {true_words}")
            edit_dist = Client.edit_distance(pred_words, true_words)
            # åˆ†æ¯å–æœ€å¤§é•¿åº¦
            denom = max(len(pred_words), len(true_words), 1)
            return edit_dist / denom

    return WERToolkit, ID_TO_CHAR


def load_final_model(args):
    """åŠ è½½æœ€ç»ˆç”Ÿæˆçš„èšåˆæ¨¡å‹"""
    try:
        # åˆå§‹åŒ–æ¨¡å‹
        model = FedAvgASRModel(
            in_channels=1,
            mel_dim=args.mel_dim,
            hidden_dim=args.hidden_dim,
            vocab_size=args.vocab_size
        ).to(args.device)

        # åŠ è½½æ¨¡å‹æƒé‡
        if torch.cuda.is_available() and args.device == "cuda":
            state_dict = torch.load(args.model_path)
        else:
            state_dict = torch.load(args.model_path, map_location=torch.device("cpu"))
        model.load_state_dict(state_dict)
        model.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
        print(f"âœ… åŠ è½½æœ€ç»ˆæ¨¡å‹æˆåŠŸï¼š{args.model_path}ï¼ˆè¿è¡Œè®¾å¤‡ï¼š{args.device}ï¼‰")
        return model
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}")
        print(f"è¯·æ£€æŸ¥ï¼š1. æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼›2. æ¨¡å‹å‚æ•°ï¼ˆmel_dim/hidden_dim/vocab_sizeï¼‰æ˜¯å¦ä¸è®­ç»ƒä¸€è‡´")
        return None


def test_model_wer(args, model, wer_toolkit):
    # 1. ç¡®å®šè¦æµ‹è¯•çš„å®¢æˆ·ç«¯IDåˆ—è¡¨
    if args.test_client_ids == "all":
        test_client_ids = list(range(10))  # é»˜è®¤æ€»å®¢æˆ·ç«¯æ•°ä¸º10
    else:
        test_client_ids = [int(cid.strip()) for cid in args.test_client_ids.split(",")]
    print(f"\nğŸ“Œ æµ‹è¯•å®¢æˆ·ç«¯åˆ—è¡¨ï¼š{test_client_ids}ï¼ˆå…±{len(test_client_ids)}ä¸ªå®¢æˆ·ç«¯ï¼‰")

    # 2. éå†å®¢æˆ·ç«¯æµ‹è¯•é›†ï¼Œè®¡ç®—æ€»WER
    total_wer = 0.0
    total_samples = 0
    client_wer_detail = []  # è®°å½•æ¯ä¸ªå®¢æˆ·ç«¯çš„WERè¯¦æƒ…

    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒåŠ é€Ÿæ¨ç†å¹¶å‡å°‘å†…å­˜å ç”¨
        for client_id in test_client_ids:
            # è¯»å–å½“å‰å®¢æˆ·ç«¯çš„æµ‹è¯•æ•°æ®
            try:
                test_data = read_client_data(
                    dataset=args.dataset,
                    idx=client_id,
                    is_train=False,  # è¯»å–æµ‹è¯•é›†
                    max_mel_len=args.max_mel_len,
                    max_text_len=args.max_text_len,
                    dict_path=args.dict_path
                )
                if len(test_data) == 0:
                    print(f"âš ï¸  å®¢æˆ·ç«¯{client_id}ï¼šæ— æµ‹è¯•æ•°æ®ï¼Œè·³è¿‡")
                    continue
            except Exception as e:
                print(f"âš ï¸  å®¢æˆ·ç«¯{client_id}ï¼šæ•°æ®è¯»å–å¤±è´¥ï¼ˆ{str(e)}ï¼‰ï¼Œè·³è¿‡")
                continue

            # æ„å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨
            test_loader = DataLoader(
                test_data, batch_size=args.batch_size, shuffle=False, drop_last=False
            )

            # è®¡ç®—å½“å‰å®¢æˆ·ç«¯çš„WER
            client_wer = 0.0
            client_sample_cnt = 0

            for batch in test_loader:
                # è§£åŒ…æ•°æ®
                mel, mel_len, text_ids, text_len = [x.to(args.device) for x in batch]
                try:
                    conv_weight = model.conv_block1[0].weight
                    conv_weight2=model.dense1.weight
                    conv_weight3 = model.dense1.bias
                    conv_weight_np = conv_weight.detach().cpu().numpy()
                    # 2. è½¬ç§»åˆ°CPUå¹¶è½¬ä¸ºnumpy
                    conv_weight_np2 = conv_weight2.detach().cpu().numpy()
                    conv_weight_np3 = conv_weight3.detach().cpu().numpy()
                    # 3. å±•å¹³å‚æ•°å¹¶å–å‰5ä¸ªå…ƒç´ 
                    first_five = conv_weight_np.flatten()[:5]
                    first_five2 = conv_weight_np2.flatten()[:5]
                    first_five3 = conv_weight_np3.flatten()[:5]
                    print(f"conv_block1.0.weightå‰äº”ä¸ªå…ƒç´ ï¼š{first_five}")
                    print(f"dense1.weightå‰äº”ä¸ªå…ƒç´ ï¼š{first_five2}")
                    print(f"dense1.biaså‰äº”ä¸ªå…ƒç´ ï¼š{first_five3}")
                except AttributeError:
                    print("è­¦å‘Šï¼šæœªæ‰¾åˆ°å‚æ•°conv_block1.0.weightï¼Œè¯·æ£€æŸ¥æ¨¡å‹ç»“æ„å‘½åæ˜¯å¦æ­£ç¡®")
                # æ¨¡å‹æ¨ç†ï¼ˆè¾“å‡ºlog_probsï¼š(batch, T', vocab_size)ï¼‰
                model.eval()
                print(f"melï¼š{mel}")
                log_probs = model(mel)
                print(f"idsï¼š{log_probs}")
                # è´ªå¿ƒè§£ç ï¼ˆå–æ¯ä¸ªæ—¶é—´æ­¥æ¦‚ç‡æœ€å¤§çš„å­—ç¬¦IDï¼‰
                pred_ids = torch.argmax(log_probs, dim=-1).cpu().numpy()

                # è§£ç ä¸ºæ–‡æœ¬ï¼ˆæ‹¼éŸ³åºåˆ—ï¼‰
                true_ids_np = text_ids.cpu().numpy()  # çœŸå®æ ‡ç­¾ID
                true_len_np = text_len.cpu().numpy()  # çœŸå®æ–‡æœ¬æœ‰æ•ˆé•¿åº¦
                pred_texts = [wer_toolkit.decode_ctc(pred) for pred in pred_ids]
                true_texts = [wer_toolkit.decode_true_text(true, tl)
                              for true, tl in zip(true_ids_np, true_len_np)]

                # ç´¯åŠ WERå’Œæ ·æœ¬æ•°
                for pred_txt, true_txt in zip(pred_texts, true_texts):
                    client_wer += wer_toolkit.calculate_wer(pred_txt, true_txt)
                    client_sample_cnt += 1

            # è®¡ç®—å½“å‰å®¢æˆ·ç«¯å¹³å‡WER
            avg_client_wer = client_wer / client_sample_cnt if client_sample_cnt > 0 else 0.0
            client_wer_detail.append({
                "client_id": client_id,
                "sample_cnt": client_sample_cnt,
                "avg_wer": avg_client_wer
            })
            total_wer += client_wer
            total_samples += client_sample_cnt

            print(f"âœ… å®¢æˆ·ç«¯{client_id}ï¼šæµ‹è¯•æ ·æœ¬æ•°={client_sample_cnt:3d}ï¼Œå¹³å‡WER={avg_client_wer:.4f}")

    # 3. è®¡ç®—æ•´ä½“å¹³å‡WERå¹¶è¾“å‡ºæ±‡æ€»
    if total_samples == 0:
        print("\nâŒ æ— æœ‰æ•ˆæµ‹è¯•æ ·æœ¬ï¼Œæ— æ³•è®¡ç®—æ•´ä½“WER")
        return

    overall_avg_wer = total_wer / total_samples
    print("\n" + "=" * 80)
    print(f"ğŸ“Š æœ€ç»ˆæ¨¡å‹WERæµ‹è¯•ç»“æœæ±‡æ€»")
    print(f"=" * 80)
    print(f"æµ‹è¯•å®¢æˆ·ç«¯æ•°é‡ï¼š{len(test_client_ids)}")
    print(f"æ€»æµ‹è¯•æ ·æœ¬æ•°é‡ï¼š{total_samples}")
    print(f"æ‰€æœ‰å®¢æˆ·ç«¯æ•´ä½“å¹³å‡WERï¼š{overall_avg_wer:.4f}")
    print(f"\nå„å®¢æˆ·ç«¯è¯¦ç»†WERï¼š")
    for detail in client_wer_detail:
        print(f"  å®¢æˆ·ç«¯{detail['client_id']}ï¼šæ ·æœ¬æ•°={detail['sample_cnt']:3d}ï¼ŒWER={detail['avg_wer']:.4f}")
    print("=" * 80)


if __name__ == "__main__":
    # 1. è§£æå‚æ•°
    args = parse_args()

    # 2. é€‚é…è®¾å¤‡
    if args.device == "cuda" and not torch.cuda.is_available():
        print("âš ï¸  æœªæ£€æµ‹åˆ°å¯ç”¨CUDAè®¾å¤‡ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°CPUè¿è¡Œ")
        args.device = "cpu"

    # 3. åˆå§‹åŒ–WERè®¡ç®—å·¥å…·
    wer_toolkit, _ = init_wer_tools(args.dict_path)

    # 4. åŠ è½½æœ€ç»ˆæ¨¡å‹
    final_model = load_final_model(args)
    if not final_model:
        exit(1)  # æ¨¡å‹åŠ è½½å¤±è´¥åˆ™é€€å‡º

    # 5. æ‰§è¡ŒWERæµ‹è¯•
    test_model_wer(args, final_model, wer_toolkit)